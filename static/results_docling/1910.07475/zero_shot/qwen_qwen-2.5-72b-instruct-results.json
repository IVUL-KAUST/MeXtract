{
    "metadata": {
        "Name": "MLQA",
        "Subsets": [
            {
                "Name": "Arabic",
                "Volume": 5852,
                "Unit": "instances",
                "Language": "Arabic"
            },
            {
                "Name": "Chinese",
                "Volume": 5641,
                "Unit": "instances",
                "Language": "Chinese"
            },
            {
                "Name": "English",
                "Volume": 12738,
                "Unit": "instances",
                "Language": "English"
            },
            {
                "Name": "German",
                "Volume": 5029,
                "Unit": "instances",
                "Language": "German"
            },
            {
                "Name": "Hindi",
                "Volume": 5425,
                "Unit": "instances",
                "Language": "Hindi"
            },
            {
                "Name": "Spanish",
                "Volume": 5753,
                "Unit": "instances",
                "Language": "Spanish"
            },
            {
                "Name": "Vietnamese",
                "Volume": 6006,
                "Unit": "instances",
                "Language": "Vietnamese"
            }
        ],
        "Link": "https://github.com/facebookresearch/mlqa",
        "HF Link": "",
        "License": "unknown",
        "Year": 2019,
        "Language": [
            "Arabic",
            "Chinese",
            "English",
            "German",
            "Hindi",
            "Spanish",
            "Vietnamese"
        ],
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling",
            "human annotation"
        ],
        "Description": "MLQA is a multi-way aligned extractive QA evaluation benchmark in seven languages: English, Arabic, German, Spanish, Hindi, Vietnamese, and Simplified Chinese.",
        "Volume": 5852.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Facebook AI Research",
            "University College London"
        ],
        "Derived From": [
            "SQuAD"
        ],
        "Paper Title": "MLQA: Evaluating Cross-lingual Extractive Question Answering",
        "Paper Link": "https://arxiv.org/abs/1910.08982",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "cross-lingual information retrieval"
        ],
        "Venue Title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
        "Venue Type": "conference",
        "Venue Name": "EMNLP-IJCNLP",
        "Authors": [
            "Holger Schwenk",
            "Patrick Lewis",
            "Barlas Ou011fuz",
            "Ruty Rinott",
            "Sebastian Riedel"
        ],
        "Affiliations": [
            "Facebook AI Research",
            "University College London"
        ],
        "Abstract": "Question answering (QA) models have shown rapid progress enabled by the availability of large, high-quality benchmark datasets. Such annotated datasets are difficult and costly to collect, and rarely exist in languages other than English, making building QA systems that work well in other languages challenging. In order to develop such systems, it is crucial to invest in high quality multilingual evaluation benchmarks to measure progress. We present MLQA, a multi-way aligned extractive QA evaluation benchmark intended to spur research in this area."
    },
    "validation": {
        "DIVERSITY": 0.0,
        "ACCESSABILITY": 0.5714285714285714,
        "CONTENT": 0.7142857142857143,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.5263157894736842
    },
    "length_forcing": 0.9999999999999999,
    "cost": {
        "cost": 0.00297854,
        "input_tokens": 19294,
        "output_tokens": 742
    },
    "config": {
        "model_name": "qwen_qwen-2.5-72b-instruct",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1910.07475"
    },
    "ratio_filling": 1.0,
    "error": null
}