{
    "metadata": {
        "Name": "Arabic-Hebrew TED talks",
        "Subsets": [],
        "Link": "http://wit3.fbk.eu/mt.php?release=2016-01-more",
        "HF Link": "",
        "License": "unknown",
        "Year": 2016,
        "Language": "multilingual",
        "Dialect": "Modern Standard Arabic",
        "Domain": [
            "captions"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "machine annotation"
        ],
        "Description": "An Arabic-Hebrew parallel corpus of TED talk subtitles, aligned and segmented into sentences using English as a pivot. Contains approximately 225,000 sentence pairs and 3.5 million tokens per language for the aligned portion.",
        "Volume": 225000.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "FBK"
        ],
        "Derived From": [
            "WIT3",
            "TED talks"
        ],
        "Paper Title": "An Arabic-Hebrew parallel corpus of TED talks",
        "Paper Link": "https://arxiv.org/abs/1610.00572",
        "Script": "Arab",
        "Tokenized": true,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Mauro Cettolo"
        ],
        "Affiliations": [
            "FBK, Trento, Italy"
        ],
        "Abstract": "We describe an Arabic-Hebrew parallel corpus of TED talks built upon WIT 3 , the Web inventory that repurposes the original content of the TED website in a way which is more convenient for MT researchers.nThe benchmark consists of about 2,000 talks, whose subtitles in Arabic and Hebrew have been accurately aligned and rearranged in sentences, for a total of about 3.5M tokens per language. Talks have been partitioned in train, development and test sets similarly in all respects to the MT tasks of the IWSLT 2016 evaluation campaign.nIn addition to describing the benchmark, we list the problems encountered in preparing it and the novel methods designed to solve them. Baseline MT results and some measures on sentence length are provided as an extrinsic evaluation of the quality of the benchmark."
    },
    "validation": {
        "DIVERSITY": 1.0,
        "ACCESSABILITY": 0.7142857142857143,
        "CONTENT": 0.875,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.8095238095238095
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.06344125,
        "input_tokens": 9027,
        "output_tokens": 538
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview",
        "few_shot": 0,
        "month": null,
        "year": "2016",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1610.00572"
    },
    "ratio_filling": 1.0,
    "error": null
}