{
    "metadata": {
        "Name": "Dangerous Speech Dataset",
        "Subsets": [
            {
                "Name": "REST API",
                "Volume": 2.8,
                "Unit": "tokens",
                "Dialect": "mixed"
            },
            {
                "Name": "Timelines",
                "Volume": 107.5,
                "Unit": "tokens",
                "Dialect": "mixed"
            }
        ],
        "Link": "https://github.com/UBC-NLP/ara_dangspeech",
        "HF Link": "",
        "License": "custom",
        "Year": 2023,
        "Language": "ar",
        "Dialect": "mixed",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "crawling"
        ],
        "Description": "The dataset focuses on dangerous speech in Arabic Twitter, specifically direct threats. It includes a manually curated multi-dialectal dictionary of physical harm threats and a large dataset of threatening speech collected from Arabic Twitter.",
        "Volume": 110.3,
        "Unit": "tokens",
        "Ethical Risks": "High",
        "Provider": [
            "SUNY at Buffalo",
            "The University of British Columbia"
        ],
        "Derived From": [],
        "Paper Title": "Understanding and Detecting Dangerous Speech in Social Media",
        "Paper Link": "https://arxiv.org/abs/2005.06608",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "offensive language detection"
        ],
        "Venue Title": "Proceedings of the 13th International Workshop on Semantic Evaluation",
        "Venue Type": "workshop",
        "Venue Name": "",
        "Authors": [
            "Ali Alshehri",
            "El Moatez Billah Nagoudi",
            "Muhammad Abdul-Mageed"
        ],
        "Affiliations": [
            "SUNY at Buffalo",
            "The University of British Columbia"
        ],
        "Abstract": "Social media communication has become a significant part of daily activity in modern societies. For this reason, ensuring safety in social media platforms is a necessity. Use of dangerous language such as physical threats in online environments is a somewhat rare, yet remains highly important. Although several works have been performed on the related issue of detecting offensive and hateful language, dangerous speech has not previously been treated in any significant way. Motivated by these observations, we report our efforts to build a labeled dataset for dangerous speech. We also exploit our dataset to develop highly effective models to detect dangerous content. Our best model performs at 59.60% macro F1, significantly outperforming a competitive baseline."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.5714285714285714,
        "CONTENT": 0.625,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.5714285714285714
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.0856725,
        "input_tokens": 33633,
        "output_tokens": 592
    },
    "config": {
        "model_name": "openai_gpt-4o",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2005.06608"
    },
    "ratio_filling": 1.0,
    "error": null
}