{
    "metadata": {
        "Name": "DaNetQA",
        "Link": "https://github.com/PragmaticsLab/DaNetQA",
        "HF Link": "",
        "License": "unknown",
        "Year": 2021,
        "Language": "ru",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation",
            "machine annotation"
        ],
        "Description": "DaNetQA is a Russian yes/no question answering dataset inspired by BoolQ, comprising natural yes/no questions paired with Wikipedia paragraphs.",
        "Volume": 2691.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "National Research University Higher School of Economics",
            "Sberbank"
        ],
        "Derived From": [
            "BoolQ"
        ],
        "Paper Title": "DaNetQA: a yes/no Question Answering Dataset for the Russian Language",
        "Paper Link": "https://arxiv.org/abs/2010.02605",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "",
        "Venue Type": "conference",
        "Venue Name": "",
        "Authors": [
            "Taisia Glushkova",
            "Alexey Machnev",
            "Alena Fenogenova",
            "Tatiana Shavrina",
            "Ekaterina Artemova",
            "Dmitry I. Ignatov"
        ],
        "Affiliations": [
            "National Research University Higher School of Economics",
            "Sberbank"
        ],
        "Abstract": "DaNetQA, a new question-answering corpus, follows BoolQ design: it comprises natural yes/no questions. Each question is paired with a paragraph from Wikipedia and an answer, derived from the paragraph. The task is to take both the question and a paragraph as input and come up with a yes/no answer, i.e. to produce a binary output. In this paper, we present a reproducible approach to DaNetQA creation and investigate transfer learning methods for task and language transferring. For task transferring we leverage three similar sentence modelling tasks: 1) a corpus of paraphrases, Paraphraser, 2) an NLI task, for which we use the Russian part of XNLI, 3) another question answering task, SberQUAD. For language transferring we use English to Russian translation together with multilingual language fine-tuning."
    },
    "validation": {
        "ACCESSABILITY": 0.7142857142857143,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.00428339,
        "input_tokens": 11054,
        "output_tokens": 510
    },
    "config": {
        "model_name": "deepseek_deepseek-chat-v3-0324",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2010.02605"
    },
    "ratio_filling": 1.0,
    "error": null
}