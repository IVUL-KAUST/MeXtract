{
    "metadata": {
        "Name": "JTubeSpeech",
        "Link": "http://www.jsc-db.info/index.html",
        "HF Link": "",
        "License": "custom",
        "Year": 2021,
        "Language": "jp",
        "Domain": [
            "social media"
        ],
        "Form": "spoken",
        "Collection Style": [
            "crawling",
            "machine annotation",
            "human annotation"
        ],
        "Description": "A large-scale Japanese speech corpus of over 2,400 hours of speech data collected from YouTube. The corpus is designed for training and evaluating automatic speech recognition (ASR) and speaker verification (SV) systems. Transcripts were machine-generated and then manually corrected.",
        "Volume": 2400.0,
        "Unit": "hours",
        "Ethical Risks": "Medium",
        "Provider": [
            "LINE Corporation"
        ],
        "Derived From": [],
        "Paper Title": "JTubeSpeech: corpus of Japanese speech collected from YouTube for speech recognition and speaker verification",
        "Paper Link": "https://arxiv.org/abs/2110.02348",
        "Script": "mixed",
        "Tokenized": false,
        "Host": "other",
        "Access": "Upon-Request",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "speech recognition",
            "speaker identification"
        ],
        "Venue Title": "Proceedings of the 2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)",
        "Venue Type": "conference",
        "Venue Name": "Asia-Pacific Signal and Information Processing Association Annual Summit and Conference",
        "Authors": [
            "Takaaki Saeki",
            "Kenta Watanabe",
            "Masaru Omura",
            "Hiroki Kanda",
            "Shota Suzuki",
            "Nobuaki Kono",
            "Takanori Ashihara"
        ],
        "Affiliations": [
            "LINE Corporation"
        ],
        "Abstract": "We present JTubeSpeech, a large-scale Japanese speech corpus of over 2,400 hours of speech data collected from YouTube. The corpus is designed for training and evaluating automatic speech recognition (ASR) and speaker verification (SV) systems. The transcripts were generated by a commercial speech recognition engine and then manually checked and corrected by human transcribers. The corpus also contains speaker labels for SV tasks. We describe the details of the corpus construction and provide baseline ASR and SV results. The experimental results show that the ASR model trained on JTubeSpeech achieves a character error rate of 4.8% on a Japanese lecture speech evaluation set, outperforming a model trained on a similarly sized corpus of Japanese broadcast recordings. The JTubeSpeech corpus is publicly available for research purposes."
    },
    "validation": {
        "ACCESSABILITY": 0.14285714285714285,
        "DIVERSITY": 1.0,
        "CONTENT": 0.625,
        "EVALUATION": 1.0,
        "AVERAGE": 0.5263157894736842
    },
    "length_forcing": 0.9999999999999999,
    "cost": {
        "cost": 0.03412125,
        "input_tokens": 3086,
        "output_tokens": 1339
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2112.09323"
    },
    "ratio_filling": 1.0,
    "error": null
}