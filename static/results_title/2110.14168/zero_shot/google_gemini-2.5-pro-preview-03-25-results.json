{
    "metadata": {
        "Name": "GSM8K",
        "Link": "https://github.com/openai/grade-school-math",
        "HF Link": "https://huggingface.co/datasets/gsm8k",
        "License": "MIT License",
        "Year": 2021,
        "Language": "en",
        "Domain": [
            "web pages"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "A dataset of 8.5K high quality, linguistically diverse grade school math word problems. The problems were created by contractors and each includes a step-by-step solution.",
        "Volume": 8500.0,
        "Unit": "documents",
        "Ethical Risks": "Low",
        "Provider": [
            "OpenAI"
        ],
        "Derived From": [],
        "Paper Title": "Training Verifiers to Solve Math Word Problems",
        "Paper Link": "https://arxiv.org/abs/2110.14168",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "commonsense reasoning"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "arXiv",
        "Authors": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano",
            "Christopher Hesse",
            "John Schulman"
        ],
        "Affiliations": [
            "OpenAI"
        ],
        "Abstract": "We introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset is segmented into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ - * /) to reach the final answer. A fine-tuned GPT-3 model solves 18% of the test set problems, while the best model solves 55% of the test set, demonstrating that the dataset is challenging for current language models. We find that training a verifier to judge the correctness of model-generated solutions is a promising direction for improving performance. We train a verifier to rank multiple solutions generated by a model, and we find that selecting the solution ranked highest by the verifier improves performance from 55% to 60%. With the verifier, we can also construct a training set for a policy via rejection sampling, which improves the policy's performance from 55% to 64%. We release our dataset, a trained verifier, and generated solutions at https://github.com/openai/grade-school-math."
    },
    "validation": {
        "ACCESSABILITY": 0.8571428571428571,
        "DIVERSITY": 1.0,
        "CONTENT": 0.7142857142857143,
        "EVALUATION": 1.0,
        "AVERAGE": 0.8333333333333334
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.03598375,
        "input_tokens": 3011,
        "output_tokens": 1588
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2110.14168"
    },
    "ratio_filling": 1.0,
    "error": null
}