{
    "metadata": {
        "Name": "FairTranslate",
        "Link": "https://github.com/GLoPensato/FairTranslate",
        "HF Link": "",
        "License": "MIT License",
        "Year": 2024,
        "Language": "multilingual",
        "Domain": [
            "public datasets",
            "other"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "human annotation"
        ],
        "Description": "An English-French dataset for evaluating gender bias in Machine Translation systems. It contains sentences with gendered terms, including non-binary pronouns, and their French translations, designed to test for gender-stereotypical translations.",
        "Volume": 1200.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Univ. Rennes",
            "CNRS",
            "IRISA",
            "Inria"
        ],
        "Derived From": [],
        "Paper Title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
        "Paper Link": "https://aclanthology.org/2024.lrec-main.415.pdf",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
        "Venue Type": "conference",
        "Venue Name": "Joint International Conference on Computational Linguistics, Language Resources and Evaluation",
        "Authors": [
            "Gabriel Lo Pensato",
            "Anouck Girard",
            "Vincent Claveau"
        ],
        "Affiliations": [
            "Univ. Rennes",
            "CNRS",
            "IRISA",
            "Inria"
        ],
        "Abstract": "The evaluation of gender bias in Natural Language Processing (NLP) has become a major research topic. In Machine Translation (MT), most studies focus on the binary dimension of gender, i.e. female and male, and do not consider non-binary gender identities. In this paper, we propose FairTranslate, a new English-French dataset for evaluating gender bias in MT systems. FairTranslate is built from scratch and contains sentences with gendered terms in English, along with their translations into French, which is a gender-marked language. The dataset is designed to evaluate the ability of MT systems to correctly translate gendered terms, including non-binary pronouns, and to avoid gender-stereotypical translations. We also propose a new metric, the Gender Accuracy Score (GAS), to evaluate the performance of MT systems on our dataset. We use FairTranslate to evaluate several state-of-the-art MT systems and show that they still struggle to correctly translate gendered terms, especially non-binary ones. Our dataset and metric are publicly available to encourage further research on gender bias in MT."
    },
    "validation": {
        "ACCESSABILITY": 0.42857142857142855,
        "DIVERSITY": 1.0,
        "CONTENT": 0.42857142857142855,
        "EVALUATION": 1.0,
        "AVERAGE": 0.5555555555555556
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.05591125,
        "input_tokens": 3025,
        "output_tokens": 1790
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2025",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2504.15941"
    },
    "ratio_filling": 1.0,
    "error": null
}