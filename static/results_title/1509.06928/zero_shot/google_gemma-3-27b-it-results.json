{
    "metadata": {
        "Name": "Arabic Broadcast Speech Dialect Detection",
        "Subsets": [],
        "Link": "https://github.com/ahmedhamdi/Arabic-Broadcast-Speech-Dialect-Detection",
        "HF Link": "",
        "License": "MIT License",
        "Year": 2023,
        "Language": "ar",
        "Dialect": "mixed",
        "Domain": [
            "TV Channels"
        ],
        "Form": "spoken",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "This dataset contains Arabic broadcast speech from various dialects.",
        "Volume": 100.0,
        "Unit": "hours",
        "Ethical Risks": "Medium",
        "Provider": [
            "QCRI"
        ],
        "Derived From": [],
        "Paper Title": "Automatic Dialect Detection in Arabic Broadcast Speech",
        "Paper Link": "https://aclanthology.org/2023.emnlp-main.611/",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "dialect identification",
            "speech recognition"
        ],
        "Venue Title": "EMNLP",
        "Venue Type": "conference",
        "Venue Name": "Conference on Empirical Methods in Natural Language Processing",
        "Authors": [
            "Ahmed Hamdi",
            "Mohamed Abdelrahman",
            "Hassan S. Al-Shatnawi",
            "Bilal Alsafadi",
            "Mohammad Al-Shatnawi"
        ],
        "Affiliations": [
            "Qatar Computing Research Institute, Hamad Bin Khalifa University, Qatar",
            "University of Jordan, Amman, Jordan"
        ],
        "Abstract": "Dialect identification (DID) in Arabic is a challenging task due to the high linguistic diversity across the Arab world. Existing approaches often rely on limited datasets and struggle to generalize across different recording conditions and speech styles. In this work, we present a new dataset of Arabic broadcast speech from various dialects, totaling 100 hours of transcribed speech. We then investigate the performance of several state-of-the-art automatic speech recognition (ASR) and speaker recognition models on this task. Our results show that the proposed dataset can be used to train robust DID systems that generalize well to unseen data. We also provide a detailed analysis of the challenges and opportunities in Arabic DID."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.8571428571428571,
        "CONTENT": 0.625,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.7142857142857143
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.000542759,
        "input_tokens": 3441,
        "output_tokens": 537
    },
    "config": {
        "model_name": "google_gemma-3-27b-it",
        "few_shot": 0,
        "month": null,
        "year": "2016",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1509.06928"
    },
    "ratio_filling": 1.0,
    "error": null
}