{
    "metadata": {
        "Name": "FairTranslate",
        "Link": "https://huggingface.co/datasets/Fannyjrd/FairTranslate_fr",
        "HF Link": "https://huggingface.co/datasets/Fannyjrd/FairTranslate_fr",
        "License": "unknown",
        "Year": 2025,
        "Language": "fr",
        "Domain": [
            "public datasets"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation",
            "machine annotation"
        ],
        "Description": "A human-annotated English-French dataset for evaluating gender bias in machine translation, focusing on non-binary gender representation",
        "Volume": 2418.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "IRT Saint Exupery",
            "Universit\u00e9 Lumi\u00e8re Lyon 2",
            "IHRIM UMR 5317",
            "ERIC"
        ],
        "Derived From": [],
        "Paper Title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
        "Paper Link": "https://doi.org/10.1145/3715275.3732013",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "FAccT '25",
        "Venue Type": "conference",
        "Venue Name": "The 2025 ACM Conference on Fairness, Accountability, and Transparency",
        "Authors": [
            "Fanny Jourdan",
            "Yannick Chevalier",
            "C\u00e9cile Favre"
        ],
        "Affiliations": [
            "IRT Saint Exupery",
            "Universit\u00e9 Lumi\u00e8re Lyon 2",
            "IHRIM UMR 5317",
            "Universit\u00e9 Lumi\u00e8re Lyon 2",
            "Universit\u00e9 Claude Bernard Lyon 1",
            "ERIC"
        ],
        "Abstract": "Large Language Models (LLMs) are increasingly leveraged for translation tasks but often fall short when translating inclusive language -- such as texts containing the singular 'they' pronoun or otherwise reflecting fair linguistic protocols. Because these challenges span both computational and societal domains, it is imperative to critically evaluate how well LLMs handle inclusive translation with a well-founded framework. This paper presents FairTranslate, a novel, fully human-annotated dataset designed to evaluate non-binary gender biases in machine translation systems from English to French. FairTranslate includes 2418 English-French sentence pairs related to occupations, annotated with rich metadata such as the stereotypical alignment of the occupation, grammatical gender indicator ambiguity, and the ground-truth gender label (male, female, or inclusive). We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B, Llama3.3-70B) on this dataset under different prompting procedures. Our results reveal substantial biases in gender representation across LLMs, highlighting persistent challenges in achieving equitable outcomes in machine translation. These findings underscore the need for focused strategies and interventions aimed at ensuring fair and inclusive language usage in LLM-based translation systems."
    },
    "validation": {
        "ACCESSABILITY": 0.42857142857142855,
        "DIVERSITY": 0.0,
        "CONTENT": 0.5714285714285714,
        "EVALUATION": 1.0,
        "AVERAGE": 0.5555555555555556
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.09468,
        "input_tokens": 24134,
        "output_tokens": 664
    },
    "config": {
        "model_name": "anthropic_claude-3.5-sonnet",
        "few_shot": 0,
        "month": null,
        "year": "2025",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2504.15941"
    },
    "ratio_filling": 1.0,
    "error": null
}