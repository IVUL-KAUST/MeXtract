{
    "metadata": {
        "Name": "REPA",
        "Link": "https://huggingface.co/datasets/RussianNLP/repa",
        "HF Link": "https://huggingface.co/datasets/RussianNLP/repa",
        "License": "MIT License",
        "Year": 2024,
        "Language": "ru",
        "Domain": [
            "public datasets"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "machine annotation",
            "human annotation"
        ],
        "Description": "REPA (Russian Error tyPes Annotation) is a dataset of 1,000 user queries and 2,000 LLM-generated responses in Russian. Each response pair is annotated by humans with preferences across ten specific error types, as well as an overall preference, to facilitate fine-grained evaluation of text generation models and LLM-as-a-judge frameworks.",
        "Volume": 1003.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "HSE University",
            "SaluteDevices",
            "University of Oslo",
            "Toloka AI"
        ],
        "Derived From": [
            "Chatbot Arena Conversations",
            "ru_instruct_gpt4",
            "Veles--2.5",
            "Tagengo",
            "Aya"
        ],
        "Paper Title": "REPA: Russian Error Types Annotation for Evaluating Text Generation and Judgment Capabilities",
        "Paper Link": "https://arxiv.org/abs/2405.18539",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "text generation",
            "linguistic acceptability",
            "natural language inference",
            "offensive language detection"
        ],
        "Venue Title": "Proceedings of the Conference of the Association for Computational Linguistics",
        "Venue Type": "conference",
        "Venue Name": "Association for Computational Linguistics",
        "Authors": [
            "Alexander Pugachev",
            "Alena Fenogenova",
            "Vladislav Mikhailov",
            "Ekaterina Artemova"
        ],
        "Affiliations": [
            "HSE University",
            "SaluteDevices",
            "University of Oslo",
            "Toloka AI"
        ],
        "Abstract": "Recent advances in large language models (LLMs) have introduced the novel paradigm of using LLMs as judges, where an LLM evaluates and scores the outputs of another LLM, which often correlates highly with human preferences. However, the use of LLM-as-a-judge has been primarily studied in English. In this paper, we evaluate this framework in Russian by introducing the Russian Error tyPes Annotation dataset (REPA), a dataset of 1k user queries and 2k LLM-generated responses. Human annotators labeled each response pair expressing their preferences across ten specific error types, as well as selecting an overall preference. We rank six generative LLMs across the error types using three rating systems based on human preferences. We also evaluate responses using eight LLM judges in zero-shot and few-shot settings. We describe the results of analyzing the judges and position and length biases. Our findings reveal a notable gap between LLM judge performance in Russian and English. However, rankings based on human and LLM preferences show partial alignment, suggesting that while current LLM judges struggle with fine-grained evaluation in Russian, there is potential for improvement."
    },
    "validation": {
        "ACCESSABILITY": 0.8571428571428571,
        "DIVERSITY": 1.0,
        "CONTENT": 0.8571428571428571,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.08075375,
        "input_tokens": 23114,
        "output_tokens": 2049
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2025",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2503.13102"
    },
    "ratio_filling": 1.0,
    "error": null
}