{
    "metadata": {
        "Name": "Flores-101",
        "Subsets": [],
        "Link": "https://github.com/facebookresearch/flores",
        "HF Link": "https://huggingface.co/datasets/flores",
        "License": "MIT License",
        "Year": 2020,
        "Language": "multilingual",
        "Dialect": "mixed",
        "Domain": [
            "news articles",
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "The Flores benchmark consists of 3001 sentences extracted from English Wikipedia and covering a variety of different topics and domains. These sentences have been translated in 101 languages by professional translators.",
        "Volume": 3001.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "Facebook AI Research"
        ],
        "Derived From": [
            "English Wikipedia"
        ],
        "Paper Title": "The Flores Evaluation Benchmark for Low-Resource and Multilingual Machine Translation",
        "Paper Link": "https://aclanthology.org/2021.eacl-main.359/",
        "Script": "Arab-Latin",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "machine translation",
            "language modeling",
            "cross-lingual information retrieval"
        ],
        "Venue Title": "EACL",
        "Venue Type": "conference",
        "Venue Name": "Conference on Computational Linguistics",
        "Authors": [
            "Naman Goyal",
            "Cynthia Gao",
            "Vishrav Chaudhary",
            "Peng-Jen Chen",
            "Guillaume Wenzek",
            "Da Ju",
            "Sanjana Krishnan",
            "Marc'Aurelio Ranzato",
            "Francisco Guzmu00e1n",
            "Angela Fan"
        ],
        "Affiliations": [
            "Facebook AI Research",
            "LORIA"
        ],
        "Abstract": "One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the lack of good evaluation benchmarks. nCurrent evaluation benchmarks either lack good coverage of low-resource languages, consider only restricted domains, or are low quality because they are constructed using semi-automatic procedures. nIn this work, we introduce the flores{} evaluation benchmark, consisting of 3001 sentences extracted from English Wikipedia and covering a variety of different topics and domains. nThese sentences have been translated in 101 languages by professional translators through a carefully controlled process. nThe resulting dataset enables better assessment of model quality on the long tail of low-resource languages, including the evaluation of many-to-many multilingual translation systems, as all translations are multilingually aligned. nBy publicly releasing such a high-quality and high-coverage dataset, we hope to foster progress in the machine translation community and beyond."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.2857142857142857,
        "CONTENT": 0.625,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.47619047619047616
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.0031878,
        "input_tokens": 9520,
        "output_tokens": 648
    },
    "config": {
        "model_name": "google_gemma-3-27b-it",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2106.03193"
    },
    "ratio_filling": 1.0,
    "error": null
}