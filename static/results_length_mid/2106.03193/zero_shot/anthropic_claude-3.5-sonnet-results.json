{
    "metadata": {
        "Name": "FLORES-101",
        "Subsets": [],
        "Link": "https://dl.fbaipublicfiles.com/flores101/dataset/flores101_dataset.tar.gz",
        "HF Link": "",
        "License": "CC BY-SA 4.0",
        "Year": 2021,
        "Language": "multilingual",
        "Dialect": "mixed",
        "Domain": [
            "news articles",
            "web pages",
            "books"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "A multilingual machine translation evaluation benchmark containing 3001 sentences from Wikipedia translated into 101 languages by professional translators with high quality control",
        "Volume": 3001.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Facebook AI Research",
            "LORIA"
        ],
        "Derived From": [],
        "Paper Title": "The FLORES-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation",
        "Paper Link": "https://arxiv.org/abs/2106.03193",
        "Script": "Arab-Latin",
        "Tokenized": false,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "EACL",
        "Venue Type": "conference",
        "Venue Name": "European Chapter of the Association for Computational Linguistics",
        "Authors": [
            "Naman Goyal",
            "Cynthia Gao",
            "Vishrav Chaudhary",
            "Peng-Jen Chen",
            "Guillaume Wenzek",
            "Da Ju",
            "Sanjana Krishnan",
            "Marc'Aurelio Ranzato",
            "Francisco Guzm\u00e1n",
            "Angela Fan"
        ],
        "Affiliations": [
            "Facebook AI Research",
            "LORIA"
        ],
        "Abstract": "One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the lack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource languages, consider only restricted domains, or are low quality because they are constructed using semi-automatic procedures. In this work, we introduce the FLORES-101 evaluation benchmark, consisting of 3001 sentences extracted from English Wikipedia and covering a variety of different topics and domains. These sentences have been translated in 101 languages by professional translators through a carefully controlled process. The resulting dataset enables better assessment of model quality on the long tail of low-resource languages, including the evaluation of many-to-many multilingual translation systems, as all translations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, we hope to foster progress in the machine translation community and beyond."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.42857142857142855,
        "CONTENT": 0.625,
        "EVALUATION": 1.0,
        "AVERAGE": 0.6190476190476191
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.119544,
        "input_tokens": 32101,
        "output_tokens": 567
    },
    "config": {
        "model_name": "anthropic_claude-3.5-sonnet",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2106.03193"
    },
    "ratio_filling": 1.0,
    "error": null
}