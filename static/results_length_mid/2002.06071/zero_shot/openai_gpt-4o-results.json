{
    "metadata": {
        "Name": "FQuAD",
        "Link": "https://illuin-tech.github.io/FQuAD-explorer/",
        "HF Link": "",
        "License": "unknown",
        "Year": 2020,
        "Language": "fr",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation"
        ],
        "Description": "FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 25,000+ samples for the 1.0 version and 60,000+ samples for the 1.1 version.",
        "Volume": 62003.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Illuin Technology",
            "ETH Zurich"
        ],
        "Derived From": [],
        "Paper Title": "FQuAD: French Question Answering Dataset",
        "Paper Link": "https://arxiv.org/abs/2002.06071",
        "Tokenized": false,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "FQuAD: French Question Answering Dataset",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Martin d'Hoffschmidt",
            "Wacim Belblidia",
            "Tom Brendl\u00e9",
            "Quentin Heinrich",
            "Maxime Vidal"
        ],
        "Affiliations": [
            "Illuin Technology",
            "ETH Zurich"
        ],
        "Abstract": "Recent advances in the field of language modeling have improved state-of-the-art results on many Natural Language Processing tasks. Among them, Reading Comprehension has made significant progress over the past few years. However, most results are reported in English since labeled resources available in other languages, such as French, remain scarce. In the present work, we introduce the French Question Answering Dataset (FQuAD). FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 25,000+ samples for the 1.0 version and 60,000+ samples for the 1.1 version. We train a baseline model which achieves an F1 score of 92.2 and an exact match ratio of 82.1 on the test set. In order to track the progress of French Question Answering models we propose a leader-board and we have made the 1.0 version of our dataset freely available at https://illuin-tech.github.io/FQuAD-explorer/. The release of a native French Reading Comprehension dataset is motivated by the release of recent French monolingual models and by industrial opportunities. In addition to that, we think that a French dataset opens up a wide range of possible experiments at the research level."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9655172413793099,
    "cost": {
        "cost": 0.068555,
        "input_tokens": 25023,
        "output_tokens": 599
    },
    "config": {
        "model_name": "openai_gpt-4o",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2002.06071"
    },
    "ratio_filling": 1.0,
    "error": null
}