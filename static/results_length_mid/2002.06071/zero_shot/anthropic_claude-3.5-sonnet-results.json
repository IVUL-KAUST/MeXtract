{
    "metadata": {
        "Name": "FQuAD",
        "Link": "https://illuin-tech.github.io/FQuAD-explorer/",
        "HF Link": "",
        "License": "unknown",
        "Year": 2020,
        "Language": "fr",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation"
        ],
        "Description": "A French native reading comprehension dataset of 60k+ question-answer pairs from Wikipedia articles",
        "Volume": 62003.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Illuin Technology",
            "CentraleSup\u00e9lec"
        ],
        "Derived From": [],
        "Paper Title": "FQuAD: French Question Answering Dataset",
        "Paper Link": "https://arxiv.org/abs/2002.06071",
        "Tokenized": false,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Martin d'Hoffschmidt",
            "Wacim Belblidia",
            "Tom Brendl\u00e9",
            "Quentin Heinrich",
            "Maxime Vidal"
        ],
        "Affiliations": [
            "Illuin Technology",
            "ETH Zurich"
        ],
        "Abstract": "Recent advances in the field of language modeling have improved state-of-the-art results on many Natural Language Processing tasks. Among them, Reading Comprehension has made significant progress over the past few years. However, most results are reported in English since labeled resources available in other languages, such as French, remain scarce. In the present work, we introduce the French Question Answering Dataset (FQuAD). FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 25,000+ samples for the 1.0 version and 60,000+ samples for the 1.1 version. We train a baseline model which achieves an F1 score of 92.2 and an exact match ratio of 82.1 on the test set."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.094899,
        "input_tokens": 25023,
        "output_tokens": 455
    },
    "config": {
        "model_name": "anthropic_claude-3.5-sonnet",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2002.06071"
    },
    "ratio_filling": 1.0,
    "error": null
}