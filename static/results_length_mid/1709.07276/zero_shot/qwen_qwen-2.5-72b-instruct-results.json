{
    "metadata": {
        "Name": "MGB-3",
        "Subsets": [
            {
                "Name": "Comedy",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "Cooking",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "FamilyKids",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "Fashion",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "Drama",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "Science",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "Sports",
                "Volume": 1.0,
                "Unit": "hours",
                "Dialect": "Egypt"
            }
        ],
        "Link": "http://www.mgb-challenge.org/workshop.html",
        "HF Link": "",
        "License": "unknown",
        "Year": 2017,
        "Language": "ar",
        "Dialect": "Egypt",
        "Domain": [
            "reviews"
        ],
        "Form": "spoken",
        "Collection Style": [
            "crawling"
        ],
        "Description": "The MGB-3 Arabic Challenge focuses on dialectal Arabic using a multi-genre collection of Egyptian YouTube videos. It includes 16 hours of data split into adaptation, development, and testing sets.",
        "Volume": 16.0,
        "Unit": "hours",
        "Ethical Risks": "Low",
        "Provider": [
            "Qatar Computing Research Institute",
            "University of Edinburgh"
        ],
        "Derived From": [
            "MGB-2"
        ],
        "Paper Title": "Speech Recognition Challenge in the Wild: Arabic MGB-3",
        "Paper Link": "http://www.mgb-challenge.org/workshop.html",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "speech recognition",
            "dialect identification"
        ],
        "Venue Title": "Speech Recognition Challenge in the Wild: Arabic MGB-3",
        "Venue Type": "conference",
        "Venue Name": "MGB-3 Workshop",
        "Authors": [
            "Ahmed Ali",
            "Stephan Vogel",
            "Steve Renals"
        ],
        "Affiliations": [
            "Qatar Computing Research Institute, HBKU, Doha, Qatar",
            "Centre for Speech Technology Research, University of Edinburgh, UK"
        ],
        "Abstract": "This paper describes the Arabic MGB-3 Challenge -- Arabic Speech Recognition in the Wild. Unlike last year's Arabic MGB-2 Challenge, for which the recognition task was based on more than 1,200 hours broadcast TV news recordings from Aljazeera Arabic TV programs, MGB-3 emphasises dialectal Arabic using a multi-genre collection of Egyptian YouTube videos. Seven genres were used for the data collection: comedy, cooking, family/kids, fashion, drama, sports, and science (TEDx). A total of 16 hours of videos, split evenly across the different genres, were divided into adaptation, development and evaluation data sets. The Arabic MGB-Challenge comprised two tasks: A) Speech transcription, evaluated on the MGB-3 test set, along with the 10 hour MGB-2 test set to report progress on the MGB-2 evaluation;  B) Arabic dialect identification, introduced this year in order to distinguish between four major Arabic dialects -- Egyptian, Levantine, North African, Gulf, as well as Modern Standard Arabic. Two hours of audio per dialect were released for development and a further two hours were used for evaluation. For dialect identification, both lexical features and i-vector bottleneck features were shared with participants in addition to the raw audio recordings.  Overall, thirteen teams submitted ten systems to the challenge.  We outline the approaches adopted in each system, and summarise the evaluation results."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.5714285714285714,
        "CONTENT": 0.875,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.6666666666666666
    },
    "length_forcing": 0.96875,
    "cost": {
        "cost": 0.0019917,
        "input_tokens": 13130,
        "output_tokens": 919
    },
    "config": {
        "model_name": "qwen_qwen-2.5-72b-instruct",
        "few_shot": 0,
        "month": null,
        "year": "2017",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1709.07276"
    },
    "ratio_filling": 1.0,
    "error": null
}