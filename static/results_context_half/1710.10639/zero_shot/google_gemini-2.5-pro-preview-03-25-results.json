{
    "metadata": {
        "Name": "JESC",
        "Link": "https://nlp.stanford.edu/projects/jesc/",
        "HF Link": "",
        "License": "unknown",
        "Year": 2018,
        "Language": "multilingual",
        "Domain": [
            "web pages",
            "captions",
            "public datasets"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling",
            "manual curation"
        ],
        "Description": "A large Japanese-English parallel corpus of 3.2 million examples from TV and movie subtitles, covering conversational dialogue. Assembled by crawling and aligning subtitles from the web, with preprocessing for quality.",
        "Volume": 3.2,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "Stanford University",
            "Rakuten Institute of Technology",
            "Google Brain"
        ],
        "Derived From": [
            "OpenSubtitles"
        ],
        "Paper Title": "JESC: Japanese-English Subtitle Corpus",
        "Paper Link": "https://aclanthology.org/L18-1544/",
        "Script": "mixed",
        "Tokenized": false,
        "Host": "other",
        "Access": "Free",
        "Cost": "0",
        "Test Split": false,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)",
        "Venue Type": "conference",
        "Venue Name": "Language Resources and Evaluation Conference",
        "Authors": [
            "Reid Pryzant",
            "Youngjoo Chung",
            "Dan Jurafsky",
            "Denny Britz"
        ],
        "Affiliations": [
            "Stanford University",
            "Rakuten Institute of Technology",
            "Google Brain"
        ],
        "Abstract": "In this paper we describe the Japanese-English Subtitle Corpus (JESC). JESC is a large Japanese-English parallel corpus covering the underrepresented domain of conversational dialogue. It consists of more than 3.2 million examples, making it the largest freely available dataset of its kind. The corpus was assembled by crawling and aligning subtitles found on the web. The assembly process incorporates a number of novel preprocessing elements to ensure high monolingual fluency and accurate bilingual alignments. We summarize its contents and evaluate its quality using human experts and baseline machine translation (MT) systems."
    },
    "validation": {
        "ACCESSABILITY": 0.42857142857142855,
        "DIVERSITY": 1.0,
        "CONTENT": 0.5,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.47368421052631576
    },
    "length_forcing": 0.9999999999999999,
    "cost": {
        "cost": 0.08526375,
        "input_tokens": 5603,
        "output_tokens": 497
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2018",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1710.10639"
    },
    "ratio_filling": 1.0,
    "error": null
}