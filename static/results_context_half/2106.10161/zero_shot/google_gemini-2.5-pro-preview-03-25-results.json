{
    "metadata": {
        "Name": "Golos",
        "Link": "https://github.com/sberdevices/golos",
        "HF Link": "",
        "License": "unknown",
        "Year": 2021,
        "Language": "ru",
        "Domain": [
            "other"
        ],
        "Form": "spoken",
        "Collection Style": [
            "manual curation",
            "human annotation",
            "other"
        ],
        "Description": "Golos is a large Russian speech dataset of approximately 1240 hours. It consists of audio recorded by humans reading template-generated texts, manually transcribed and validated via crowd-sourcing. It is intended for speech recognition research.",
        "Volume": 1240.0,
        "Unit": "hours",
        "Ethical Risks": "Low",
        "Provider": [
            "Sber"
        ],
        "Derived From": [],
        "Paper Title": "Golos: Russian Dataset for Speech Research",
        "Paper Link": "https://www.isca-speech.org/archive/pdfs/interspeech_2021/karpov21_interspeech.pdf",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "speech recognition",
            "language modeling"
        ],
        "Venue Title": "INTERSPEECH 2021",
        "Venue Type": "conference",
        "Venue Name": "INTERSPEECH",
        "Authors": [
            "Nikolay Karpov",
            "Alexander Denisenko",
            "Fedor Minkin"
        ],
        "Affiliations": [
            "Sber, Russia"
        ],
        "Abstract": "This paper introduces a novel Russian speech dataset called Golos, a large corpus suitable for speech research. The dataset mainly consists of recorded audio files manually annotated on the crowd-sourcing platform. The total duration of the audio is about 1240 hours. We have made the corpus freely available to download, along with the acoustic model with CTC loss prepared on this corpus. Additionally, transfer learning was applied to improve the performance of the acoustic model. In order to evaluate the quality of the dataset with the beam-search algorithm, we have built a 3-gram language model on the open Common Crawl dataset. The total word error rate (WER) metrics turned out to be about 3.3% and 11.5%."
    },
    "validation": {
        "ACCESSABILITY": 0.7142857142857143,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 1.0,
        "AVERAGE": 0.8888888888888888
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.09265625,
        "input_tokens": 6002,
        "output_tokens": 523
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2106.10161"
    },
    "ratio_filling": 1.0,
    "error": null
}