{
    "metadata": {
        "Name": "FrenchMedMCQA",
        "Link": "http://www.remede.org/internat/pharmacie/qcm-internat.html",
        "HF Link": "",
        "License": "unknown",
        "Year": 2022,
        "Language": "fr",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "FrenchMedMCQA is the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for the medical domain, containing 3,105 questions from real French pharmacy exams.",
        "Volume": 3105.0,
        "Unit": "tokens",
        "Ethical Risks": "Low",
        "Provider": [
            "LIA - Avignon University",
            "LS2N - Nantes University",
            "CHU de Nantes - La clinique des donn\u00e9es - Nantes University",
            "Zenidoc"
        ],
        "Derived From": [],
        "Paper Title": "FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain",
        "Paper Link": "https://arxiv.org/abs/2304.04280",
        "Tokenized": false,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "multiple choice question answering"
        ],
        "Venue Title": "",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Yanis Labrak",
            "Adrien Bazoge",
            "Richard Dufour",
            "B\u00e9atrice Daille",
            "Pierre-Antoine Gourraud",
            "Emmanuel Morin",
            "Mickael Rouvier"
        ],
        "Affiliations": [
            "LIA - Avignon University",
            "LS2N - Nantes University",
            "CHU de Nantes - La clinique des donn\u00e9es - Nantes University",
            "Zenidoc"
        ],
        "Abstract": "This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online."
    },
    "validation": {
        "ACCESSABILITY": 0.2857142857142857,
        "DIVERSITY": 1.0,
        "CONTENT": 0.5714285714285714,
        "EVALUATION": 1.0,
        "AVERAGE": 0.5555555555555556
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.00263151,
        "input_tokens": 5769,
        "output_tokens": 564
    },
    "config": {
        "model_name": "deepseek_deepseek-chat-v3-0324",
        "few_shot": 0,
        "month": null,
        "year": "2023",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2304.04280"
    },
    "ratio_filling": 1.0,
    "error": null
}