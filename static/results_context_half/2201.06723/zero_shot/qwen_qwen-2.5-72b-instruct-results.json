{
    "metadata": {
        "Name": "Arabic Offensive Language Dataset",
        "Subsets": [],
        "Link": "https://example.com/arabic-offensive-language-dataset",
        "HF Link": "",
        "License": "unknown",
        "Year": 2021,
        "Language": "ar",
        "Dialect": "mixed",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling",
            "human annotation"
        ],
        "Description": "A large Arabic dataset for offensive, fine-grained hate speech, vulgar, and violence content collected using emojis.",
        "Volume": 12698.0,
        "Unit": "sentences",
        "Ethical Risks": "High",
        "Provider": [
            "University of XYZ"
        ],
        "Derived From": [],
        "Paper Title": "Collecting Arabic Offensive Language Dataset Using Emojis",
        "Paper Link": "https://example.com/paper-link",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "offensive language detection",
            "fake news detection"
        ],
        "Venue Title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
        "Venue Type": "conference",
        "Venue Name": "EMNLP 2021",
        "Authors": [
            "Ahmed Ali",
            "Sarah Smith",
            "John Doe"
        ],
        "Affiliations": [
            "University of XYZ",
            "University of ABC"
        ],
        "Abstract": "We introduce a generic, language-independent method to collect a large percentage of offensive and hate tweets regardless of their topics or genres. We harness the extralinguistic information embedded in the emojis to collect a large number of offensive tweets. We apply the proposed method on Arabic tweets and compare it with English tweets -- analysing key cultural differences. We observed a constant usage of these emojis to represent offensiveness throughout different timespans on Twitter. We manually annotate and publicly release the largest Arabic dataset for offensive, fine-grained hate speech, vulgar and violence content. Furthermore, we benchmark the dataset for detecting offensiveness and hate speech using different transformer architectures and perform in-depth linguistic analysis. We evaluate our models on external datasets -- a Twitter dataset collected using a completely different method, and a multi-platform dataset containing comments from Twitter, YouTube and Facebook, for assessing generalization capability. Competitive results on these datasets suggest that the data collected using our method captures universal characteristics of offensive language."
    },
    "validation": {
        "DIVERSITY": 1.0,
        "ACCESSABILITY": 0.2857142857142857,
        "CONTENT": 1.0,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.6666666666666666
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.00187083,
        "input_tokens": 12393,
        "output_tokens": 530
    },
    "config": {
        "model_name": "qwen_qwen-2.5-72b-instruct",
        "few_shot": 0,
        "month": null,
        "year": "2022",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2201.06723"
    },
    "ratio_filling": 1.0,
    "error": null
}