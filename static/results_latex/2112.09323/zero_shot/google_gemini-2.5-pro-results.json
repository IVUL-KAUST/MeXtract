{
    "metadata": {
        "Name": "JTubeSpeech",
        "Link": "https://github.com/sarulab-speech/jtubespeech",
        "HF Link": "",
        "License": "unknown",
        "Year": 2022,
        "Language": "jp",
        "Domain": [
            "web pages"
        ],
        "Form": "spoken",
        "Collection Style": [
            "crawling",
            "machine annotation",
            "human annotation"
        ],
        "Description": "A large-scale Japanese speech corpus collected from YouTube videos and their subtitles. It is designed for both automatic speech recognition (ASR) and automatic speaker verification (ASV) tasks, containing over 1,300 hours for ASR and 900 hours for ASV.",
        "Volume": 1376.9,
        "Unit": "hours",
        "Ethical Risks": "Medium",
        "Provider": [
            "The University of Tokyo",
            "Technical University of Munich",
            "Tokyo Metropolitan University",
            "Carnegie Mellon University"
        ],
        "Derived From": [],
        "Paper Title": "JTubeSpeech: corpus of Japanese speech collected from YouTube for speech recognition and speaker verification",
        "Paper Link": "https://arxiv.org/abs/2112.03233",
        "Script": "mixed",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "speech recognition",
            "speaker identification"
        ],
        "Venue Title": "2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "Venue Type": "conference",
        "Venue Name": "IEEE International Conference on Acoustics, Speech and Signal Processing",
        "Authors": [
            "Shinnosuke Takamichi",
            "Ludwig K\u00fcrzinger",
            "Takaaki Saeki",
            "Sayaka Shiota",
            "Shinji Watanabe"
        ],
        "Affiliations": [
            "The University of Tokyo, Japan",
            "Technical University of Munich, Germany",
            "Tokyo Metropolitan University, Japan",
            "Carnegie Mellon University, USA"
        ],
        "Abstract": "In this paper, we construct a new Japanese speech corpus called 'JTubeSpeech.' Although recent end-to-end learning requires large-size speech corpora, open-sourced such corpora for languages other than English have not yet been established. In this paper, we describe the construction of a corpus from YouTube videos and subtitles for speech recognition and speaker verification. Our method can automatically filter the videos and subtitles with almost no language-dependent processes. We consistently employ Connectionist Temporal Classification (CTC)-based techniques for automatic speech recognition (ASR) and a speaker variation-based method for automatic speaker verification (ASV). We build 1) a large-scale Japanese ASR benchmark with more than 1,300 hours of data and 2) 900 hours of data for Japanese ASV."
    },
    "validation": {},
    "cost": {
        "cost": 0.0488575,
        "input_tokens": 11987,
        "output_tokens": 1259
    },
    "config": {
        "model_name": "google_gemini-2.5-pro",
        "few_shot": 0,
        "month": null,
        "year": null,
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/pdf/2112.09323"
    },
    "ratio_filling": 1.0,
    "error": null
}