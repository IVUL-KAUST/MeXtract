{
    "metadata": {
        "Name": "FQuAD2.0",
        "Link": "https://huggingface.co/datasets/illuin/fquad2",
        "HF Link": "https://huggingface.co/datasets/illuin/fquad2",
        "License": "unknown",
        "Year": 2020,
        "Language": "fr",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation"
        ],
        "Description": "FQuAD2.0 is a French Question Answering dataset that extends FQuAD1.1 with over 17,000 adversarially annotated unanswerable questions. Sourced from Wikipedia articles, it contains a total of nearly 80,000 questions, designed to train models that can abstain from answering when no answer is present in the context.",
        "Volume": 79768.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Illuin Technology"
        ],
        "Derived From": [
            "FQuAD1.1"
        ],
        "Paper Title": "FQuAD2.0: French Question Answering and knowing that you know nothing",
        "Paper Link": "https://aclanthology.org/2020.emnlp-main.481",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
        "Venue Type": "conference",
        "Venue Name": "Conference on Empirical Methods in Natural Language Processing",
        "Authors": [
            "Quentin Heinrich",
            "Gautier Viaud",
            "Wacim Belblidia"
        ],
        "Affiliations": [
            "Illuin Technology"
        ],
        "Abstract": "Question Answering, including Reading Comprehension, is one of the NLP research areas that has seen significant scientific breakthroughs over the past few years, thanks to the concomitant advances in Language Modeling. Most of these breakthroughs, however, are centered on the English language. In 2020, as a first strong initiative to bridge the gap to the French language, Illuin Technology introduced FQuAD1.1, a French Native Reading Comprehension dataset composed of 60,000+ questions and answers samples extracted from Wikipedia articles. Nonetheless, Question Answering models trained on this dataset have a major drawback: they are not able to predict when a given question has no answer in the paragraph of interest, therefore making unreliable predictions in various industrial use-cases. In the present work, we introduce FQuAD2.0, which extends FQuAD with 17,000+ unanswerable questions, annotated adversarially, in order to be similar to answerable ones. This new dataset, comprising a total of almost 80,000 questions, makes it possible to train French Question Answering models with the ability of distinguishing unanswerable questions from answerable ones. We benchmark several models with this dataset: our best model, a fine-tuned CamemBERTtextsubscript{LARGE}, achieves a F1 score of 82.3% on this classification task, and a F1 score of 83% on the Reading Comprehension task."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 1.0,
        "AVERAGE": 0.8333333333333334
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.06212875,
        "input_tokens": 14933,
        "output_tokens": 1716
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2021",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2109.13209"
    },
    "ratio_filling": 1.0,
    "error": null
}