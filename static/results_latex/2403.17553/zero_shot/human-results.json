{
    "metadata": {
        "Name": "RuBia",
        "Link": "https://github.com/vergrig/RuBia-Dataset",
        "HF Link": "",
        "License": "CC BY-SA 4.0",
        "Year": 2024,
        "Language": "ru",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "human annotation"
        ],
        "Description": "RuBia is a Russian language bias detection dataset divided into 4 domains: gender, nationality, socio-economic status, and diverse. Each example consists of two sentences, one reinforcing a harmful stereotype and the other contradicting it. The data was written by volunteers and validated by crowdworkers.",
        "Volume": 1989.0,
        "Unit": "sentences",
        "Ethical Risks": "High",
        "Provider": [
            "HSE University"
        ],
        "Derived From": [],
        "Paper Title": "RuBia: A Russian Language Bias Detection Dataset",
        "Paper Link": "https://arxiv.org/pdf/2403.17553",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "other"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "arXiv",
        "Authors": [
            "Veronika Grigoreva",
            "Anastasiia Ivanova",
            "Ilseyar Alimova",
            "Ekaterina Artemova"
        ],
        "Affiliations": [
            "Queen\u2019s University",
            "Higher School of Economics",
            "Wildberries",
            "Linguistic Convergence Laboratory",
            "Toloka AI"
        ],
        "Abstract": "Warning: this work contains upsetting or disturbing content. Large language models (LLMs) tend to learn the social and cultural biases present in the raw pre-training data. To test if a LLM\u2019s behavior is fair, functional datasets are employed, and due to their purpose, these datasets are highly language and culture-specific. In this paper, we address a gap in the scope of multilingual bias evaluation by presenting a bias detection dataset specifically designed for the Russian language, dubbed as RuBia. The RuBia dataset is divided into 4 domains: gender, nationality, socio-economic status, and diverse, each of the domains is further divided into multiple fine-grained subdomains. Every example in the dataset consists of two sentences with the first reinforcing a potentially harmful stereotype or trope and the second contradicting it. Thesesentencepairswerefirst written by volunteers and then validated by native-speaking crowdsourcing workers. Overall, there are nearly 2,000 unique sentence pairs spread over 19 subdomains in RuBia. To illustrate the dataset\u2019s purpose, we conduct a diagnostic evaluation of state-of-the-art or near-state-of-the-art LLMs and discuss the LLMs\u2019 predisposition to social biases.",
        "annotations_from_paper": {
            "Name": 1,
            "Link": 1,
            "HF Link": 0,
            "License": 1,
            "Year": 1,
            "Language": 1,
            "Domain": 1,
            "Form": 1,
            "Collection Style": 1,
            "Description": 1,
            "Volume": 1,
            "Unit": 1,
            "Ethical Risks": 1,
            "Provider": 1,
            "Derived From": 1,
            "Paper Title": 1,
            "Paper Link": 1,
            "Tokenized": 1,
            "Host": 1,
            "Access": 1,
            "Cost": 1,
            "Test Split": 1,
            "Tasks": 1,
            "Venue Title": 1,
            "Venue Type": 1,
            "Venue Name": 1,
            "Authors": 1,
            "Affiliations": 1,
            "Abstract": 1
        }
    },
    "validation": {
        "ACCESSABILITY": 1.0,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 1.0,
        "AVERAGE": 1.0
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0,
        "input_tokens": 0,
        "output_tokens": 0
    },
    "config": {
        "model_name": "human",
        "few_shot": 0,
        "month": null,
        "year": "2024",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2403.17553"
    },
    "ratio_filling": 1.0,
    "error": null
}