{
    "metadata": {
        "Name": "WikiOmnia",
        "Link": "https://huggingface.co/datasets/RussianNLP/wikiomnia",
        "HF Link": "https://huggingface.co/datasets/RussianNLP/wikiomnia",
        "License": "unknown",
        "Year": 2021,
        "Language": "ru",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "LLM generated",
            "manual curation"
        ],
        "Description": "WikiOmnia is a large Russian QA dataset generated from Russian Wikipedia summaries using ruGPT-3 XL and ruT5-large models. It includes two parts: a raw dataset with 15.9 million QA pairs and a filtered dataset with 3.5 million QA pairs.",
        "Volume": 15921913.0,
        "Unit": "hours",
        "Ethical Risks": "Low",
        "Provider": [
            "Artificial Intelligence Research Institute (AIRI)",
            "SberDevices"
        ],
        "Derived From": [
            "SberQuAD"
        ],
        "Paper Title": "WikiOmnia: filtration and evaluation of the generated QA corpus on the whole Russian Wikipedia",
        "Paper Link": "https://example.com/paper-link",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "machine translation"
        ],
        "Venue Title": "LREC 2022",
        "Venue Type": "conference",
        "Venue Name": "Language Resources and Evaluation Conference",
        "Authors": [
            "Dina Pisarevskaya",
            "Tatiana Shavrina"
        ],
        "Affiliations": [
            "Independent Researcher",
            "Artificial Intelligence Research Institute (AIRI)",
            "SberDevices"
        ],
        "Abstract": "The General QA field has been developing the methodology referencing the Stanford Question answering dataset (SQuAD) as the significant benchmark. Compiling factual questions datasets requires manual annotations, limiting the training data's potential size. We present the WikiOmnia dataset, a new publicly available set of QA pairs and corresponding Russian Wikipedia article summary sections, composed with a fully automated generation and filtration pipeline. To ensure high quality of generated QA pairs, diverse manual and automated evaluation techniques were applied. The WikiOmnia pipeline is available open-source and is also tested for creating SQuAD-formatted QA on other domains, like news texts, fiction, and social media."
    },
    "validation": {
        "ACCESSABILITY": 0.8571428571428571,
        "DIVERSITY": 1.0,
        "CONTENT": 0.5714285714285714,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.6666666666666666
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.00198929,
        "input_tokens": 12914,
        "output_tokens": 521
    },
    "config": {
        "model_name": "qwen_qwen-2.5-72b-instruct",
        "few_shot": 0,
        "month": null,
        "year": "2022",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2204.08009"
    },
    "ratio_filling": 1.0,
    "error": null
}