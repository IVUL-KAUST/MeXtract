{
    "metadata": {
        "Name": "FairTranslate",
        "Link": "https://github.com/fanny-jourdan/FairTranslate",
        "HF Link": "",
        "License": "unknown",
        "Year": 2025,
        "Language": "multilingual",
        "Domain": [
            "LLM"
        ],
        "Form": "text",
        "Collection Style": [
            "LLM generated",
            "human annotation"
        ],
        "Description": "An English-French dataset for evaluating non-binary gender bias in machine translation. It contains 2,418 human-annotated sentence pairs about occupations, with metadata for gender (male, female, inclusive), stereotype alignment, and ambiguity, designed to test LLMs' handling of inclusive language like the singular 'they'.",
        "Volume": 2418.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "IRT Saint Exupery",
            "Universit\u00e9 Lumi\u00e8re Lyon 2",
            "Universit\u00e9 Claude Bernard Lyon 1"
        ],
        "Derived From": [],
        "Paper Title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
        "Paper Link": "https://doi.org/10.1145/3715275.3732013",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "machine translation"
        ],
        "Venue Title": "The 2025 ACM Conference on Fairness, Accountability, and Transparency",
        "Venue Type": "conference",
        "Venue Name": "FAccT\u201925",
        "Authors": [
            "Fanny Jourdan",
            "Yannick Chevalier",
            "C\u00e9cile Favre"
        ],
        "Affiliations": [
            "IRT Saint Exupery",
            "Universit\u00e9 Lumi\u00e8re Lyon 2",
            "Universit\u00e9 Claude Bernard Lyon 1, ERIC"
        ],
        "Abstract": "Large Language Models (LLMs) are increasingly leveraged for translation tasks but often fall short when translating inclusive language \u2013 such as texts containing the singular 'they' pronoun or otherwise reflecting fair linguistic protocols. Because these challenges span both computational and societal domains, it is imperative to critically evaluate how well LLMs handle inclusive translation with a well-founded framework. This paper presents FairTranslate, a novel, fully human-annotated dataset designed to evaluate non-binary gender biases in machine translation systems from English to French. FairTranslate includes 2418 English-French sentence pairs related to occupations, annotated with rich metadata such as the stereotypical alignment of the occupation, grammatical gender indicator ambiguity, and the ground-truth gender label (male, female, or inclusive). We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B, Llama3.3-70B) on this dataset under different prompting procedures. Our results reveal substantial biases in gender representation across LLMs, highlighting persistent challenges in achieving equitable outcomes in machine translation. These findings underscore the need for focused strategies and interventions aimed at ensuring fair and inclusive language usage in LLM-based translation systems. We make the FairTranslate dataset publicly available on Hugging Face, and disclose the code for all experiments on GitHub."
    },
    "validation": {},
    "cost": {
        "cost": 0.06674375,
        "input_tokens": 22020,
        "output_tokens": 1591
    },
    "config": {
        "model_name": "google_gemini-2.5-pro",
        "few_shot": 0,
        "month": null,
        "year": null,
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/pdf/2504.15941"
    },
    "ratio_filling": 1.0,
    "error": null
}