{
    "metadata": {
        "Name": "Polyglot-NER",
        "Subsets": [
            {
                "Name": "ar",
                "Volume": 11000000.0,
                "Unit": "tokens",
                "Dialect": "Modern Standard Arabic"
            }
        ],
        "Link": "https://sites.google.com/site/rmyeid/projects/polyglot-ner",
        "HF Link": "",
        "License": "CC BY-SA 3.0",
        "Year": 2015,
        "Language": "multilingual",
        "Dialect": "Modern Standard Arabic",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling",
            "machine annotation"
        ],
        "Description": "A massive multilingual dataset for Named Entity Recognition derived from Wikipedia snapshots and annotated using Freebase across 40 languages.",
        "Volume": 11000000.0,
        "Unit": "tokens",
        "Ethical Risks": "Low",
        "Provider": [
            "Google Research"
        ],
        "Derived From": [
            "Wikipedia",
            "Freebase"
        ],
        "Paper Title": "Polyglot-NER: Massive Multilingual Named Entity Recognition",
        "Paper Link": "https://epubs.siam.org/doi/abs/10.1137/1.9781611974010.19",
        "Script": "Arab",
        "Tokenized": true,
        "Host": "other",
        "Access": "Free",
        "Cost": "",
        "Test Split": false,
        "Tasks": [
            "named entity recognition"
        ],
        "Venue Title": "Proceedings of the 2015 SIAM International Conference on Data Mining (SDM)",
        "Venue Type": "conference",
        "Venue Name": "SIAM International Conference on Data Mining",
        "Authors": [
            "Rami Al-Rfou",
            "Vivek Kulkarni",
            "Bryan Perozzi",
            "Steven Skiena"
        ],
        "Affiliations": [
            "Google Research"
        ],
        "Abstract": "Named Entity Recognition (NER) is a fundamental task in natural language processing. It requires large amounts of labeled data to achieve high performance using supervised learning methods. However, creating labeled data is an expensive and laborious process, especially for a large number of languages. In this paper, we present a method for automatically creating massive labeled NER data for potentially any language using Wikipedia and Freebase. We generate data for 40 languages and demonstrate its utility by training state-of-the-art NER models. The resulting models significantly outperform Stanford NER models on the CoNLL datasets for Spanish and Dutch, without using any labeled data for these languages. We release the data and models for public use."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.2857142857142857,
        "CONTENT": 0.75,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.5714285714285714
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.08557999999999999,
        "input_tokens": 14740,
        "output_tokens": 1171
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25-browsing",
        "few_shot": 0,
        "month": null,
        "year": "2014",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1410.3791"
    },
    "ratio_filling": 1.0,
    "error": null
}