{
    "metadata": {
        "Name": "JCoLA",
        "Link": "https://github.com/osekilab/JCoLA",
        "HF Link": "",
        "License": "custom",
        "Year": 2023,
        "Language": "jp",
        "Domain": [
            "books"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation"
        ],
        "Description": "JCoLA (Japanese Corpus of Linguistic Acceptability) consists of 10,020 sentences annotated with binary acceptability judgments. The sentences are manually extracted from linguistics textbooks, handbooks, and journal articles, and are split into in-domain and out-of-domain data.",
        "Volume": 10020.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "The University of Tokyo"
        ],
        "Derived From": [],
        "Paper Title": "JCoLA: Japanese Corpus of Linguistic Acceptability",
        "Paper Link": "https://arxiv.org/pdf/2309.12676",
        "Script": "mixed",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "linguistic acceptability"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Taiga Someya",
            "Yushi Sugimoto",
            "Yohei Oseki"
        ],
        "Affiliations": [
            "The University of Tokyo"
        ],
        "Abstract": "Neural language models have exhibited outstanding performance in a range of downstream tasks. However, there is limited understanding regarding the extent to which these models internalize syntactic knowledge, so that various datasets have recently been constructed to facilitate syntactic evaluation of language models across languages. In this paper, we introduce JCoLA (Japanese Corpus of Linguistic Acceptability), which consists of 10,020 sentences annotated with binary acceptability judgments. Specifically, those sentences are manually extracted from linguistics textbooks, handbooks and journal articles, and split into in-domain data (86%; relatively simple acceptability judgments extracted from textbooks and handbooks) and out-of-domain data (14 %; theoretically significant acceptability judgments extracted from journal articles), the latter of which is categorized by 12 linguistic phenomena. We then evaluate the syntactic knowledge of 9 different types of Japanese language models on JCoLA. The results demonstrated that several models could surpass human performance for the in-domain data, while no models were able to exceed human performance for the out-of-domain data. Error analyses by linguistic phenomena further revealed that although neural language models are adept at handling local syntactic dependencies like argument structure, their performance wanes when confronted with long-distance syntactic dependencies like verbal agreement and NPI licensing.",
        "annotations_from_paper": {
            "Name": 1,
            "Link": 1,
            "HF Link": 0,
            "License": 0,
            "Year": 1,
            "Language": 1,
            "Domain": 1,
            "Form": 1,
            "Collection Style": 1,
            "Description": 1,
            "Volume": 1,
            "Unit": 1,
            "Ethical Risks": 1,
            "Provider": 1,
            "Derived From": 1,
            "Paper Title": 1,
            "Paper Link": 1,
            "Script": 1,
            "Tokenized": 1,
            "Host": 1,
            "Access": 1,
            "Cost": 1,
            "Test Split": 1,
            "Tasks": 1,
            "Venue Title": 1,
            "Venue Type": 1,
            "Venue Name": 1,
            "Authors": 1,
            "Affiliations": 1,
            "Abstract": 1
        }
    },
    "validation": {
        "ACCESSABILITY": 1.0,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 1.0,
        "AVERAGE": 1.0
    },
    "length_forcing": 0.9999999999999999,
    "cost": {
        "cost": 0,
        "input_tokens": 0,
        "output_tokens": 0
    },
    "config": {
        "model_name": "human",
        "few_shot": 0,
        "month": null,
        "year": "2023",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2309.12676"
    },
    "ratio_filling": 1.0,
    "error": null
}