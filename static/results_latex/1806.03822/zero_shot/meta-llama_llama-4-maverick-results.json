{
    "metadata": {
        "Name": "SQuAD 2.0",
        "Link": "https://bit.ly/2rDHBgY",
        "HF Link": "",
        "License": "CC BY-SA 4.0",
        "Year": 2018,
        "Language": "en",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation",
            "manual curation"
        ],
        "Description": "SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones.",
        "Volume": 130319.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Stanford University"
        ],
        "Derived From": [
            "SQuAD 1.1"
        ],
        "Paper Title": "Know What You Don't Know: Unanswerable Questions for SQuAD",
        "Paper Link": "https://www.aclweb.org/anthology/N18-2124/",
        "Tokenized": false,
        "Host": "CodaLab",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
        "Venue Type": "conference",
        "Venue Name": "NAACL-HLT 2018",
        "Authors": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "Affiliations": [
            "Computer Science Department, Stanford University"
        ],
        "Abstract": "We present SQuAD 2.0, a new version of the Stanford Question Answering Dataset. SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 1.0,
        "CONTENT": 0.8571428571428571,
        "EVALUATION": 1.0,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.00225195,
        "input_tokens": 14628,
        "output_tokens": 526
    },
    "config": {
        "model_name": "meta-llama_llama-4-maverick",
        "few_shot": 0,
        "month": null,
        "year": "2018",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1806.03822"
    },
    "ratio_filling": 1.0,
    "error": null
}