{
    "metadata": {
        "Name": "RuCoLA",
        "Link": "https://rucola-benchmark.com/",
        "HF Link": "https://huggingface.co/datasets/RussianNLP/rucola",
        "License": "Apache-2.0",
        "Year": 2023,
        "Language": "ru",
        "Domain": [
            "books",
            "web pages",
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "machine annotation"
        ],
        "Description": "RuCoLA is a novel benchmark of 13.4k sentences labeled as acceptable or not. It combines in-domain sentences from linguistic literature and out-of-domain sentences produced by generative models.",
        "Volume": 13445.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "SberDevices",
            "ABBYY",
            "HSE University",
            "Yandex",
            "Huawei Noah's Ark Lab",
            "LMU Munich"
        ],
        "Derived From": [],
        "Paper Title": "RuCoLA: Russian Corpus of Linguistic Acceptability",
        "Paper Link": "https://arxiv.org/abs/2210.12814",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "language modeling",
            "text generation",
            "offensive language detection",
            "Linguistic acceptability"
        ],
        "Venue Title": "",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Vladislav Mikhailov",
            "Tatiana Shamardina",
            "Max Ryabinin",
            "Alena Pestova",
            "Ivan Smurov",
            "Ekaterina Artemova"
        ],
        "Affiliations": [
            "SberDevices",
            "ABBYY",
            "HSE University",
            "Yandex",
            "Huawei Noah's Ark Lab",
            "Center for Information and Language Processing (CIS), MaiNLP lab, LMU Munich"
        ],
        "Abstract": "Linguistic acceptability (LA) attracts the attention of the research community due to its many uses, such as testing the grammatical knowledge of language models and filtering implausible texts with acceptability classifiers. However, the application scope of LA in languages other than English is limited due to the lack of high-quality resources. To this end, we introduce the Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up under the well-established binary LA approach. RuCoLA consists of 9.8k in-domain sentences from linguistic publications and 3.6k out-of-domain sentences produced by generative models. The out-of-domain set is created to facilitate the practical use of acceptability for improving language generation. Our paper describes the data collection protocol and presents a fine-grained analysis of acceptability classification experiments with a range of baseline approaches. In particular, we demonstrate that the most widely used language models still fall behind humans by a large margin, especially when detecting morphological and semantic errors. We release RuCoLA, the code of experiments, and a public leaderboard to assess the linguistic competence of language models for Russian."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 1.0,
        "CONTENT": 0.5714285714285714,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.5555555555555556
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.004036378,
        "input_tokens": 31349,
        "output_tokens": 1405
    },
    "config": {
        "model_name": "google_gemma-3-27b-it-browsing",
        "few_shot": 0,
        "month": null,
        "year": "2022",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2210.12814"
    },
    "ratio_filling": 1.0,
    "error": null
}