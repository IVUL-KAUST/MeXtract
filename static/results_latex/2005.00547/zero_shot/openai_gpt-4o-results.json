{
    "metadata": {
        "Name": "GoEmotions",
        "Link": "https://github.com/google-research/google-research/tree/master/goemotions",
        "HF Link": "",
        "License": "unknown",
        "Year": 2020,
        "Language": "en",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "machine annotation"
        ],
        "Description": "GoEmotions is a dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. It is the largest manually annotated dataset for fine-grained emotion prediction.",
        "Volume": 58009.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "Google Research"
        ],
        "Derived From": [],
        "Paper Title": "GoEmotions: A Dataset of Fine-Grained Emotions",
        "Paper Link": "https://arxiv.org/pdf/2005.00547.pdf",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "emotion classification"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Dorottya Demszky",
            "Dana Movshovitz-Attias",
            "Jeongwoo Ko",
            "Alan Cowen",
            "Gaurav Nemade",
            "Sujith Ravi"
        ],
        "Affiliations": [
            "Stanford Linguistics",
            "Google Research",
            "Amazon Alexa"
        ],
        "Abstract": "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement."
    },
    "validation": {
        "ACCESSABILITY": 0.7142857142857143,
        "DIVERSITY": 1.0,
        "CONTENT": 0.8571428571428571,
        "EVALUATION": 1.0,
        "AVERAGE": 0.8333333333333334
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.0488775,
        "input_tokens": 19197,
        "output_tokens": 491
    },
    "config": {
        "model_name": "openai_gpt-4o",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2005.00547"
    },
    "ratio_filling": 1.0,
    "error": null
}