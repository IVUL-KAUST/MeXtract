{
    "metadata": {
        "Name": "GoEmotions",
        "Link": "https://github.com/google-research/google-research/tree/master/goemotions",
        "HF Link": "",
        "License": "unknown",
        "Year": 2020,
        "Language": "en",
        "Domain": [
            "social media"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation",
            "crawling"
        ],
        "Description": "A dataset of 58k English Reddit comments labeled for 27 emotion categories or Neutral.",
        "Volume": 58000.0,
        "Unit": "sentences",
        "Ethical Risks": "Medium",
        "Provider": [
            "Google Research",
            "Stanford Linguistics"
        ],
        "Derived From": [
            "Reddit comments"
        ],
        "Paper Title": "GoEmotions: A Dataset of Fine-Grained Emotions",
        "Paper Link": "https://arxiv.org/abs/2005.00547",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "emotion classification"
        ],
        "Venue Title": "ACL 2020",
        "Venue Type": "conference",
        "Venue Name": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
        "Authors": [
            "Dorottya Demszky",
            "Dana Movshovitz-Attias",
            "Jeongwoo Ko",
            "Alan Cowen",
            "Gaurav Nemade",
            "Sujith Ravi"
        ],
        "Affiliations": [
            "Stanford Linguistics",
            "Google Research",
            "Amazon Alexa"
        ],
        "Abstract": "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement."
    },
    "validation": {
        "ACCESSABILITY": 0.7142857142857143,
        "DIVERSITY": 1.0,
        "CONTENT": 0.8571428571428571,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.7777777777777778
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.0037282,
        "input_tokens": 19197,
        "output_tokens": 499
    },
    "config": {
        "model_name": "meta-llama_llama-4-maverick",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2005.00547"
    },
    "ratio_filling": 1.0,
    "error": null
}