{
    "metadata": {
        "Name": "MGB-3",
        "Subsets": [
            {
                "Name": "ADI Egyptian",
                "Volume": 16.4,
                "Unit": "hours",
                "Dialect": "Egypt"
            },
            {
                "Name": "ADI Gulf",
                "Volume": 14.1,
                "Unit": "hours",
                "Dialect": "Gulf"
            },
            {
                "Name": "ADI Levantine",
                "Volume": 14.3,
                "Unit": "hours",
                "Dialect": "Levant"
            },
            {
                "Name": "ADI Modern Standard Arabic",
                "Volume": 14.3,
                "Unit": "hours",
                "Dialect": "Modern Standard Arabic"
            },
            {
                "Name": "ADI North African",
                "Volume": 14.6,
                "Unit": "hours",
                "Dialect": "North Africa"
            }
        ],
        "Link": "http://www.mgb-challenge.org",
        "HF Link": "",
        "License": "unknown",
        "Year": 2017,
        "Language": "ar",
        "Dialect": "Egypt",
        "Domain": [
            "TV Channels",
            "social media"
        ],
        "Form": "spoken",
        "Collection Style": [
            "crawling",
            "human annotation"
        ],
        "Description": "MGB-3 is a 16-hour Egyptian Arabic speech dataset from YouTube videos across seven genres (comedy, cooking, family/kids, fashion, drama, sports, science), created for the MGB-3 Challenge ASR task. It features multiple manual transcriptions. The challenge also included an ADI task using a separate multi-dialect dataset.",
        "Volume": 16.0,
        "Unit": "hours",
        "Ethical Risks": "Medium",
        "Provider": [
            "Qatar Computing Research Institute, HBKU",
            "Centre for Speech Technology Research, University of Edinburgh"
        ],
        "Derived From": [],
        "Paper Title": "Speech Recognition Challenge in the Wild: Arabic MGB-3",
        "Paper Link": "https://arxiv.org/abs/1709.07276",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "other",
        "Access": "Upon-Request",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "speech recognition",
            "dialect identification"
        ],
        "Venue Title": "Proceedings of the MGB Challenge Workshop",
        "Venue Type": "workshop",
        "Venue Name": "MGB Challenge Workshop",
        "Authors": [
            "Ahmed Ali",
            "Stephan Vogel",
            "Steve Renals"
        ],
        "Affiliations": [
            "Qatar Computing Research Institute, HBKU, Doha, Qatar",
            "Centre for Speech Technology Research, University of Edinburgh, UK"
        ],
        "Abstract": "This paper describes the Arabic MGB-3 Challenge -- Arabic Speech Recognition in the Wild. Unlike last year's Arabic MGB-2 Challenge, for which the recognition task was based on more than 1,200 hours broadcast TV news recordings from Aljazeera Arabic TV programs, MGB-3 emphasises dialectal Arabic using a multi-genre collection of Egyptian YouTube videos. Seven genres were used for the data collection: comedy, cooking, family/kids, fashion, drama, sports, and science (TEDx). A total of 16 hours of videos, split evenly across the different genres, were divided into adaptation, development and evaluation data sets. The Arabic MGB-Challenge comprised two tasks: A) Speech transcription, evaluated on the MGB-3 test set, along with the 10 hour MGB-2 test set to report progress on the MGB-2 evaluation; B) Arabic dialect identification, introduced this year in order to distinguish between four major Arabic dialects -- Egyptian, Levantine, North African, Gulf, as well as Modern Standard Arabic. Two hours of audio per dialect were released for development and a further two hours were used for evaluation. For dialect identification, both lexical features and i-vector bottleneck features were shared with participants in addition to the raw audio recordings. Overall, thirteen teams submitted ten systems to the challenge. We outline the approaches adopted in each system, and summarise the evaluation results."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.2857142857142857,
        "CONTENT": 0.625,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.5238095238095238
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.12084,
        "input_tokens": 15027,
        "output_tokens": 918
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 3,
        "month": null,
        "year": "2017",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1709.07276"
    },
    "ratio_filling": 1.0,
    "error": null
}