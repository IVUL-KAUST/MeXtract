{
    "metadata": {
        "Name": "RuBQ",
        "Link": "http://doi.org/10.5281/zenodo.3835913",
        "HF Link": "",
        "License": "CC BY-SA 1.0",
        "Year": 2020,
        "Language": "ru",
        "Domain": [
            "captions",
            "web pages"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling",
            "crawling",
            "LLM generated",
            "manual curation"
        ],
        "Description": "RuBQ is the first Russian KBQA dataset, consisting of 1,500 questions, their English translations, SPARQL queries, and a subset of Wikidata with Russian labels.",
        "Volume": 1500.0,
        "Unit": "tokens",
        "Ethical Risks": "Low",
        "Provider": [
            "JetBrains Research"
        ],
        "Derived From": [],
        "Paper Title": "RuBQ: A Russian Dataset for Question Answering over Wikidata",
        "Paper Link": "https://arxiv.org/abs/2005.10659",
        "Tokenized": false,
        "Host": "zenodo",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "dependency parsing"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "",
        "Authors": [
            "Vladislav Korablinov",
            "Pavel Braslavski"
        ],
        "Affiliations": [
            "ITMO University, Saint Petersburg, Russia",
            "JetBrains Research, Saint Petersburg, Russia",
            "Ural Federal University, Yekaterinburg, Russia"
        ],
        "Abstract": "The paper presents RuBQ, the first Russian knowledge base question answering (KBQA) dataset. The high-quality dataset consists of 1,500 Russian questions of varying complexity, their English machine translations, SPARQL queries to Wikidata, reference answers, as well as a Wikidata sample of triples containing entities with Russian labels. The dataset creation started with a large collection of question-answer pairs from online quizzes. The data underwent automatic filtering, crowd-assisted entity linking, automatic generation of SPARQL queries, and their subsequent in-house verification."
    },
    "validation": {
        "ACCESSABILITY": 0.5714285714285714,
        "DIVERSITY": 0.0,
        "CONTENT": 0.5714285714285714,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.5555555555555556
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.00192531,
        "input_tokens": 12820,
        "output_tokens": 471
    },
    "config": {
        "model_name": "qwen_qwen-2.5-72b-instruct",
        "few_shot": 3,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2005.10659"
    },
    "ratio_filling": 1.0,
    "error": null
}