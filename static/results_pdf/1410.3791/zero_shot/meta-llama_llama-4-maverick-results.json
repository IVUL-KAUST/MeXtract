{
    "metadata": {
        "Name": "POLYGLOT-NER",
        "Subsets": [],
        "Link": "https://github.com/rami-alrfou/polyglot-ner",
        "HF Link": "",
        "License": "MIT License",
        "Year": 2013,
        "Language": "multilingual",
        "Dialect": "mixed",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "crawling"
        ],
        "Description": "A multilingual NER system for 40 languages using Wikipedia and Freebase",
        "Volume": 0.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Stony Brook University"
        ],
        "Derived From": [
            "Wikipedia",
            "Freebase"
        ],
        "Paper Title": "POLYGLOT-NER: Massive Multilingual Named Entity Recognition",
        "Paper Link": "https://aclanthology.org/K13-1023.pdf",
        "Script": "Arab",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "named entity recognition"
        ],
        "Venue Title": "CoNLL",
        "Venue Type": "conference",
        "Venue Name": "Conference on Natural Language Learning",
        "Authors": [
            "Rami Al-Rfou",
            "Vivek Kulkarni",
            "Bryan Perozzi",
            "Steven Skiena"
        ],
        "Affiliations": [
            "Department of Computer Science, Stony Brook University"
        ],
        "Abstract": "The increasing diversity of languages used on the web introduces a new level of complexity to Information Retrieval (IR) systems. We can no longer assume that textual content is written in one language or even the same language family. In this paper, we demonstrate how to build massive multilingual Named Entity Recognition (NER) annotators with minimal human expertise and intervention. We describe a system that builds NER annotators for 40 major languages using Wikipedia and Freebase. Our approach does not require NER human annotated datasets or language specific resources like treebanks, parallel corpora, or orthographic rules. The novelty of our approach lies in using only language agnostic techniques, while achieving competitive performance."
    },
    "validation": {
        "DIVERSITY": 0.6666666666666666,
        "ACCESSABILITY": 0.42857142857142855,
        "CONTENT": 0.625,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.5238095238095238
    },
    "length_forcing": 1.0,
    "cost": {
        "cost": 0.0034518,
        "input_tokens": 15984,
        "output_tokens": 481
    },
    "config": {
        "model_name": "meta-llama_llama-4-maverick",
        "few_shot": 0,
        "month": null,
        "year": "2014",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/1410.3791"
    },
    "ratio_filling": 1.0,
    "error": null
}