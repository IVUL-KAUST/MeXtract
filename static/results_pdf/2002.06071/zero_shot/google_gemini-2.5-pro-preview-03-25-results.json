{
    "metadata": {
        "Name": "FQuAD",
        "Link": "https://illuin-tech.github.io/FQuAD-explorer/",
        "HF Link": "",
        "License": "unknown",
        "Year": 2020,
        "Language": "fr",
        "Domain": [
            "wikipedia"
        ],
        "Form": "text",
        "Collection Style": [
            "manual curation",
            "human annotation"
        ],
        "Description": "FQuAD is a French native Reading Comprehension dataset with over 60,000 question-answer pairs from Wikipedia articles. It includes FQuAD1.0 (25k+ samples) and FQuAD1.1 (60k+ samples). Designed to advance French QA models.",
        "Volume": 62003.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Illuin Technology"
        ],
        "Derived From": [
            "Wikipedia"
        ],
        "Paper Title": "FQuAD: French Question Answering Dataset",
        "Paper Link": "https://arxiv.org/abs/2002.06071",
        "Tokenized": false,
        "Host": "GitHub",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering"
        ],
        "Venue Title": "arXiv",
        "Venue Type": "preprint",
        "Venue Name": "arXiv",
        "Authors": [
            "Martin d\u2019Hoffschmidt",
            "Wacim Belblidia",
            "Tom Brendl\u00e9",
            "Quentin Heinrich",
            "Maxime Vidal"
        ],
        "Affiliations": [
            "Illuin Technology",
            "ETH Zurich"
        ],
        "Abstract": "Recent advances in the field of language modeling have improved state-of-the-art results on many Natural Language Processing tasks. Among them, Reading Comprehension has made significant progress over the past few years. However, most results are reported in English since labeled resources available in other languages, such as French, remain scarce. In the present work, we introduce the French Question Answering Dataset (FQuAD). FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 25,000+ samples for the 1.0 version and 60,000+ samples for the 1.1 version. We train a baseline model which achieves an F1 score of 92.2 and an exact match ratio of 82.1 on the test set. In order to track the progress of French Question Answering models we propose a leader-board and we have made the 1.0 version of our dataset freely available at https://illuin-tech.github.io/FQuAD-explorer/."
    },
    "validation": {
        "ACCESSABILITY": 0.42857142857142855,
        "DIVERSITY": 1.0,
        "CONTENT": 1.0,
        "EVALUATION": 0.6666666666666666,
        "AVERAGE": 0.7222222222222222
    },
    "length_forcing": 0.9999999999999996,
    "cost": {
        "cost": 0.1040675,
        "input_tokens": 21631,
        "output_tokens": 607
    },
    "config": {
        "model_name": "google_gemini-2.5-pro-preview-03-25",
        "few_shot": 0,
        "month": null,
        "year": "2020",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2002.06071"
    },
    "ratio_filling": 1.0,
    "error": null
}