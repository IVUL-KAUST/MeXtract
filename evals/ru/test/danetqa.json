{
    "Name": "DaNetQA",
    "Link": "https://github.com/PragmaticsLab/DaNetQA",
    "HF_Link": "https://huggingface.co/datasets/AlexSham/DaNetQA_for_BERT",
    "License": "CC0",
    "Year": 2020,
    "Language": "ru",
    "Domain": [
        "wikipedia"
    ],
    "Form": "text",
    "Collection_Style": [
        "human annotation",
        "machine annotation",
        "manual curation"
    ],
    "Description": "DaNetQA is a question-answering dataset for the Russian language. It comprises natural yes/no questions paired with a paragraph from Wikipedia and an answer derived from the paragraph. The task is to take both the question and a paragraph as input and come up with a yes/no answer.",
    "Volume": 2691.0,
    "Unit": "sentences",
    "Ethical_Risks": "Low",
    "Provider": [
        "Pragmatics Lab"
    ],
    "Derived_From": [],
    "Paper_Title": "DaNetQA: a yes/no Question Answering Dataset for the Russian Language",
    "Paper_Link": "https://arxiv.org/pdf/2010.02605",
    "Tokenized": false,
    "Host": "GitHub",
    "Access": "Free",
    "Cost": "",
    "Test_Split": true,
    "Tasks": [
        "question answering"
    ],
    "Venue_Title": "arXiv",
    "Venue_Type": "preprint",
    "Venue_Name": "",
    "Authors": [
        "Taisia Glushkova",
        "Alexey Machnev",
        "Alena Fenogenova",
        "Tatiana Shavrina",
        "Ekaterina Artemova",
        "Dmitry I. Ignatov"
    ],
    "Affiliations": [
        "National Research University Higher School of Economics",
        "Sberbank"
    ],
    "Abstract": "DaNetQA, a new question-answering corpus, follows (Clark et. al, 2019) design: it comprises natural yes/no questions. Each question is paired with a paragraph from Wikipedia and an answer, derived from the paragraph. The task is to take both the question and a paragraph as input and come up with a yes/no answer, i.e. to produce a binary output. In this paper, we present a reproducible approach to DaNetQA creation and investigate transfer learning methods for task and language transferring. For task transferring we leverage three similar sentence modelling tasks: 1) a corpus of paraphrases, Paraphraser, 2) an NLI task, for which we use the Russian part of XNLI, 3) another question answering task, SberQUAD. For language transferring we use English to Russian translation together with multilingual language fine-tuning.",
    "annotations_from_paper": {
        "Name": 1,
        "Link": 1,
        "HF_Link": 0,
        "License": 0,
        "Year": 1,
        "Language": 1,
        "Domain": 1,
        "Form": 1,
        "Collection_Style": 1,
        "Description": 1,
        "Volume": 1,
        "Unit": 1,
        "Ethical_Risks": 1,
        "Provider": 0,
        "Derived_From": 1,
        "Paper_Title": 1,
        "Paper_Link": 1,
        "Tokenized": 1,
        "Host": 1,
        "Access": 1,
        "Cost": 1,
        "Test_Split": 1,
        "Tasks": 1,
        "Venue_Title": 1,
        "Venue_Type": 1,
        "Venue_Name": 1,
        "Authors": 1,
        "Affiliations": 1,
        "Abstract": 1
    }
}