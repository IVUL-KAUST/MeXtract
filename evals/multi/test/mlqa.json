{
    "Name": "MLQA",
    "Subsets": [
        {
            "Name": "en",
            "Volume": 12738.0,
            "Unit": "sentences",
            "Language": "English"
        },
        {
            "Name": "ar",
            "Volume": 5852.0,
            "Unit": "sentences",
            "Language": "Arabic"
        },
        {
            "Name": "de",
            "Volume": 5029.0,
            "Unit": "sentences",
            "Language": "German"
        },
        {
            "Name": "vi",
            "Volume": 6006.0,
            "Unit": "sentences",
            "Language": "Vietnamese"
        },
        {
            "Name": "es",
            "Volume": 5770.0,
            "Unit": "sentences",
            "Language": "Spanish"
        },
        {
            "Name": "zh",
            "Volume": 5852.0,
            "Unit": "sentences",
            "Language": "Simplified Chinese"
        },
        {
            "Name": "hi",
            "Volume": 5425.0,
            "Unit": "sentences",
            "Language": "Hindi"
        }
    ],
    "HF_Link": "https://hf.co/datasets/facebook/mlqa",
    "Link": "https://github.com/facebookresearch/mlqa",
    "License": "CC BY-SA 3.0",
    "Year": 2020,
    "Language": [
        "English",
        "Arabic",
        "German",
        "Vietnamese",
        "Spanish",
        "Simplified Chinese",
        "Hindi"
    ],
    "Domain": [
        "wikipedia"
    ],
    "Form": "text",
    "Collection_Style": [
        "crawling",
        "machine annotation",
        "human annotation"
    ],
    "Description": "MLQA has over 12K instances in English and 5K in each other language, with each instance parallel between 4 languages on average.",
    "Volume": 46461.0,
    "Unit": "documents",
    "Ethical_Risks": "Low",
    "Provider": [
        "Facebook"
    ],
    "Derived_From": [],
    "Paper_Title": "MLQA: Evaluating Cross-lingual Extractive Question Answering",
    "Paper_Link": "https://arxiv.org/pdf/1910.07475",
    "Tokenized": false,
    "Host": "GitHub",
    "Access": "Free",
    "Cost": "",
    "Test_Split": true,
    "Tasks": [
        "question answering"
    ],
    "Venue_Title": "arXiv",
    "Venue_Type": "preprint",
    "Venue_Name": "",
    "Authors": [
        "Patrick Lewis",
        "Barlas O\u011fuz",
        "Ruty Rinott",
        "S. Riedel",
        "Holger Schwenk"
    ],
    "Affiliations": [
        "Facebook AI Research;University College London"
    ],
    "Abstract": "Question answering (QA) models have shown rapid progress enabled by the availability of large, high-quality benchmark datasets. Such annotated datasets are difficult and costly to collect, and rarely exist in languages other than English, making training QA systems in other languages challenging. An alternative to building large monolingual training datasets is to develop cross-lingual systems which can transfer to a target language without requiring training data in that language. In order to develop such systems, it is crucial to invest in high quality multilingual evaluation benchmarks to measure progress. We present MLQA, a multi-way aligned extractive QA evaluation benchmark intended to spur research in this area. MLQA contains QA instances in 7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and Simplified Chinese. It consists of over 12K QA instances in English and 5K in each other language, with each QA instance being parallel between 4 languages on average. MLQA is built using a novel alignment context strategy on Wikipedia articles, and serves as a cross-lingual extension to existing extractive QA datasets. We evaluate current state-of-the-art cross-lingual representations on MLQA, and also provide machine-translation-based baselines. In all cases, transfer results are shown to be significantly behind training-language performance.",
    "annotations_from_paper": {
        "Name": 1,
        "Subsets": 1,
        "HF_Link": 0,
        "Link": 1,
        "License": 0,
        "Year": 1,
        "Language": 1,
        "Domain": 1,
        "Form": 1,
        "Collection_Style": 1,
        "Description": 1,
        "Volume": 1,
        "Unit": 1,
        "Ethical_Risks": 1,
        "Provider": 1,
        "Derived_From": 1,
        "Paper_Title": 1,
        "Paper_Link": 1,
        "Tokenized": 1,
        "Host": 1,
        "Access": 1,
        "Cost": 1,
        "Test_Split": 1,
        "Tasks": 1,
        "Venue_Title": 1,
        "Venue_Type": 1,
        "Venue_Name": 1,
        "Authors": 1,
        "Affiliations": 1,
        "Abstract": 1
    }
}