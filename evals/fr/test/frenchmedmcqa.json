{
    "Name": "FrenchMedMCQA",
    "Link": "https://github.com/qanastek/FrenchMedMCQA",
    "HF_Link": "https://huggingface.co/datasets/qanastek/frenchmedmcqa",
    "License": "Apache-2.0",
    "Year": 2023,
    "Language": "fr",
    "Domain": [
        "web pages"
    ],
    "Form": "text",
    "Collection_Style": [
        "manual curation"
    ],
    "Description": "FrenchMedMCQA is a multiple-choice question answering dataset in French for the medical domain. It contains 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers.",
    "Volume": 3105.0,
    "Unit": "sentences",
    "Ethical_Risks": "Medium",
    "Provider": [
        "Avignon University",
        "Nantes University",
        "Zenidoc"
    ],
    "Derived_From": [],
    "Paper_Title": "FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain",
    "Paper_Link": "https://arxiv.org/pdf/2304.04280",
    "Tokenized": false,
    "Host": "GitHub",
    "Access": "Free",
    "Cost": "",
    "Test_Split": true,
    "Tasks": [
        "multiple choice question answering"
    ],
    "Venue_Title": "arXiv",
    "Venue_Type": "preprint",
    "Venue_Name": "",
    "Authors": [
        "Yanis Labrak",
        "Adrien Bazoge",
        "Richard Dufour",
        "B\u00e9atrice Daille",
        "Pierre-Antoine Gourraud",
        "Emmanuel Morin",
        "Mickael Rouvier"
    ],
    "Affiliations": [
        "LIA - Avignon University",
        "LS2N - Nantes University",
        "CHU de Nantes - La clinique des donn\u00e9es - Nantes University",
        "Zenidoc"
    ],
    "Abstract": "This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online.",
    "annotations_from_paper": {
        "Name": 1,
        "Link": 1,
        "HF_Link": 0,
        "License": 0,
        "Year": 1,
        "Language": 1,
        "Domain": 1,
        "Form": 1,
        "Collection_Style": 1,
        "Description": 1,
        "Volume": 1,
        "Unit": 1,
        "Ethical_Risks": 1,
        "Provider": 1,
        "Derived_From": 1,
        "Paper_Title": 1,
        "Paper_Link": 1,
        "Tokenized": 1,
        "Host": 1,
        "Access": 1,
        "Cost": 1,
        "Test_Split": 1,
        "Tasks": 1,
        "Venue_Title": 1,
        "Venue_Type": 1,
        "Venue_Name": 1,
        "Authors": 1,
        "Affiliations": 1,
        "Abstract": 1
    }
}