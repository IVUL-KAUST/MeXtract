{
    "Name": "HellaSwag",
    "Link": "https://rowanzellers.com/hellaswag",
    "HF Link": "https://huggingface.co/datasets/Rowan/hellaswag",
    "License": "MIT License",
    "Year": 2019,
    "Language": "en",
    "Domain": [
        "captions",
        "public datasets",
        "wikipedia"
    ],
    "Form": "text",
    "Collection Style": [
        "crawling",
        "manual curation"
    ],
    "Description": "A new challenge dataset for commonsense natural language inference. Though its questions are trivial for humans, state-of-the-art models struggle.",
    "Volume": 70000.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "Allen Institute of Artificial Intelligence"
    ],
    "Derived From": [
        "ActivityNet"
    ],
    "Paper Title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
    "Paper Link": "https://arxiv.org/pdf/1905.07830",
    "Tokenized": false,
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": true,
    "Tasks": [
        "natural language inference"
    ],
    "Venue Title": "ACL",
    "Venue Type": "conference",
    "Venue Name": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    "Authors": [
        "Rowan Zellers",
        "Ari Holtzman",
        "Yonatan Bisk",
        "Ali Farhadi",
        "Yejin Choi"
    ],
    "Affiliations": [
        "University of Washington",
        "Allen Institute of Artificial Intelligence"
    ],
    "Abstract": "A woman is outside with a bucket and a dog. The dog is running around trying to avoid a bath. She\u2026 Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as \u201cA woman sits at a piano,\u201d a machine must select the most likely followup: \u201cShe sets her fingers on the keys.\u201d With the introduction of BERT (Devlin et al., 2018), near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (\u010595% accuracy), state-of-the-art models struggle (\u010348%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical \u2018Goldilocks\u2019 zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models.",
    "annotations_from_paper": {
        "Name": 1,
        "Link": 1,
        "HF Link": 0,
        "License": 0,
        "Year": 1,
        "Language": 1,
        "Domain": 1,
        "Form": 1,
        "Collection Style": 1,
        "Description": 0,
        "Volume": 1,
        "Unit": 1,
        "Ethical Risks": 0,
        "Provider": 1,
        "Derived From": 1,
        "Paper Title": 1,
        "Paper Link": 0,
        "Tokenized": 0,
        "Host": 0,
        "Access": 1,
        "Cost": 1,
        "Test Split": 1,
        "Tasks": 1,
        "Venue Title": 0,
        "Venue Type": 0,
        "Venue Name": 0,
        "Authors": 1,
        "Affiliations": 1,
        "Abstract": 1
    }
}